# Apache Spark
* This is an open-source distributed computing system that is designed for big data processing and analytics.
* HDFS (Hadoop Distributed File System): It's a distributed file system. HDFS is highly fault-tolerant and is designed to be deployed on low-cost hardware. It provides high throughput access to application data and is suitable for applications that have large data sets.
* MapReduce is a programming model and processing framework designed for processing and generating large datasets in a distributed computing environment. 
* RDD (Resilient Distributed Dataset) is a fundamental data structure in Apache Spark. 
* Components:
  * Spark Core: It provides distributed task scheduling, memory management, fault recovery, and interaction with storage systems. Spark Core also includes the Resilient Distributed Dataset (RDD) API, which represents a distributed collection of objects that can be operated on in parallel.
  * Spark SQL: It provides a programming interface for working with structured data within Spark. It allows users to run SQL queries, as well as perform SQL-like operations
  * Spark Streaming: It enables real-time processing of streaming data. 
  * MLlib: MLlib is Spark's scalable machine learning library. It provides a wide range of machine learning algorithms and utilities
  * GraphX: It provides a distributed graph processing framework built on top of Spark's RDD abstraction. GraphX enables users to manipulate and analyze graph-structured data, such as social networks or web graphs, using a range of graph algorithms and operators.
 
  ![image](https://github.com/MohammadNazeri/my-educations/assets/109389707/df91cdd3-9156-4b72-bb7a-a4b7c37e18e2)

